#include <cassert>
#include <iostream>
#include <numeric>
#include <optional>
#include <span>
#include <unordered_map>
#include <unordered_set>

#include <celerity.h>
#include <fmt/format.h>
#include <fmt/ranges.h>
#include <gmsh.h>

#include "hash.h"

// Knowledgebase:
//
// - Tags: Each elementary entity (point, line, plane surface, ...) can be given a "tag" (a unique positive integer),
//   which is later used to identify it when composing it into another primitive (e.g. choosing points of a line)
//   => As far as I can tell tags are unique within a type of primitive, but not across types
// - Physical groups: This is an optional feature to group entities semantically, e.g. "left wing" of a plane

// NEXT STEPS:
// - [x] I think the best way forward is to try and build the volume/face connectivity information
//   directly from the adjacency information in the mesh.
// - [ ] Start with a 2D triangulated mesh, then later try 3D tetrahedral
// - [ ] Figure out what ghost cells are when partitioning
// - [x] Figure out how to debug the simulation - view in gmsh? VTK?
// - [ ] I hope we don't need this but here is a general method for computing cell volume:
//       https://www.youtube.com/watch?v=x2CsJUE8bZo
//
//
// - Open question: How large can we scale this up..?!
// - Also look for some related work for FVM mesh generation in HPC
//   => If gmsh doesn't scale well, I think it be okay to generate a simple mesh (like a grid)
//      ad-hoc for larger runs, as long as the interface works for both (I want the stanford bunny image!!)
// - We require meshes to be pre-partitioned. Can we relax this for multi-GPU? I.e., we do the partitioning
//   across GPUs? What would this require? Implicit reductions? inter-device USM global memory atomics? (Is that
//   even a thing?)
//
// - As far as I can tell, cells inside a partition generated by gmsh are absolutely not numbered contiguously
//   If we were to store them as is, we would have an extremely fragmented buffer
//   However, we cannot simply rename them, because we need to be able to map the results back to the original mesh
//   => WHAT TO DO?!
//   => Although, if we construct dynamic data by walking over inner and outer cells per-partition, they will be dense!
//
//
// MORE NEXT STEPS:
// - Designate outer cells in each partition, these are cells that touch ghost cells
// - For every neighboring partition pair, we need to compute the intersection of the ghost cells and the partition's
//   (outer) cells
// - Initially do this manually, as in peters code: Each outer cell that is read by another partition has a copy
//   that is written when updating the outer cells
//    => We could also not do this, however it will probably lead to very fragmented memory accesses when
//    sending/receiving
//
// - Things that Celerity could do for us:
// 	- Overlap execution of inner and outer update (we get this for free)
//  - Automatically manage copies for each outer cell -> ghost cell copy
//        (create in send-segment for peer, automatically copy values)
//		=> Or: Could we do completely without the copies? Isn't this ultimately just an overlapping
//		   write + implicit reduction?
//  - Potentially launch update of each set of ghost cells (per peer) separately
//    and re-compute values => potential for more computation/communication overlap
//
// THEN, LATER:
// - Celerity should assign neighboring chunks to GPUs on the same rank
// - In theory we only need the set of outer cells on all ranks, right? In order to compute everything we need
//    => Maybe we can use this to scale the whole thing up
//

// Implementation from Boost.ContainerHash, licensed under the Boost Software License, Version 1.0.
inline void hash_combine(std::size_t& seed, std::size_t value) { seed ^= value + 0x9e3779b9 + (seed << 6) + (seed >> 2); }

class edge {
  public:
	edge(size_t from, size_t to) : m_from(std::min(from, to)), m_to(std::max(from, to)) {}

	size_t from() const { return m_from; }
	size_t to() const { return m_to; }

	bool operator==(const edge& other) const { return m_from == other.m_from && m_to == other.m_to; }

  private:
	size_t m_from;
	size_t m_to;
};

namespace std {
template <>
struct hash<edge> {
	size_t operator()(const edge& f) const {
		std::size_t seed = 0;
		hash_combine(seed, std::hash<size_t>{}(f.from()));
		hash_combine(seed, std::hash<size_t>{}(f.to()));
		return seed;
	}
};
} // namespace std

void print_entities() {
	std::vector<std::pair<int, int>> entities;
	gmsh::model::getEntities(entities);

	for(const auto& [dim, tag] : entities) {
		// Mesh data is made of `elements' (points, lines, triangles, ...), defined
		// by an ordered list of their `nodes'. Elements and nodes are identified by
		// `tags' as well (strictly positive identification numbers), and are stored
		// ("classified") in the model entity they discretize. Tags for elements and
		// nodes are globally unique (and not only per dimension, like entities).

		// A model entity of dimension 0 (a geometrical point) will contain a mesh
		// element of type point, as well as a mesh node. A model curve will contain
		// line elements as well as its interior nodes, while its boundary nodes
		// will be stored in the bounding model points. A model surface will contain
		// triangular and/or quadrangular elements and all the nodes not classified
		// on its boundary or on its embedded entities. A model volume will contain
		// tetrahedra, hexahedra, etc. and all the nodes not classified on its
		// boundary or on its embedded entities.

		// Get the mesh nodes for the entity (dim, tag):
		std::vector<std::size_t> nodeTags;
		std::vector<double> nodeCoords, nodeParams;
		gmsh::model::mesh::getNodes(nodeTags, nodeCoords, nodeParams, dim, tag);

		// Get the mesh elements for the entity (dim, tag):
		std::vector<int> elemTypes;
		std::vector<std::vector<std::size_t>> elemTags, elemNodeTags;
		gmsh::model::mesh::getElements(elemTypes, elemTags, elemNodeTags, dim, tag);

		// Elements can also be obtained by type, by using `getElementTypes()'
		// followed by `getElementsByType()'.

		// Let's print a summary of the information available on the entity and its
		// mesh.

		// * Type of the entity:
		std::string type;
		gmsh::model::getType(dim, tag, type);
		std::string name;
		gmsh::model::getEntityName(dim, tag, name);
		if(name.size()) name += " ";
		std::cout << "Entity " << name << "(dim=" << dim << ", tag=" << tag << ") of type " << type << "\n";

		// * Number of mesh nodes and elements:
		int numElem = 0;
		for(auto& tags : elemTags)
			numElem += tags.size();
		std::cout << " - Mesh has " << nodeTags.size() << " nodes and " << numElem << " elements\n";

		// * Upward and downward adjacencies:
		std::vector<int> up, down;
		gmsh::model::getAdjacencies(dim, tag, up, down);
		if(up.size()) {
			std::cout << " - Upward adjacencies (dim " << dim + 1 << "): ";
			for(auto e : up)
				std::cout << e << " ";
			std::cout << "\n";
		}
		if(down.size()) {
			std::cout << " - Downward adjacencies (dim " << dim - 1 << "): ";
			for(auto e : down)
				std::cout << e << " ";
			std::cout << "\n";
		}

		// * Does the entity belong to physical groups?
		std::vector<int> physicalTags;
		gmsh::model::getPhysicalGroupsForEntity(dim, tag, physicalTags);
		if(physicalTags.size()) {
			std::cout << " - Physical group: ";
			for(auto physTag : physicalTags) {
				std::string n;
				gmsh::model::getPhysicalName(dim, physTag, n);
				if(n.size()) n += " ";
				std::cout << n << "(" << dim << ", " << physTag << ") ";
			}
			std::cout << "\n";
		}

		// * Is the entity a partition entity? If so, what is its parent entity?
		std::vector<int> partitions;
		gmsh::model::getPartitions(dim, tag, partitions);
		if(partitions.size()) {
			std::cout << " - Partition tags:";
			for(auto part : partitions)
				std::cout << " " << part;
			int parentDim, parentTag;
			gmsh::model::getParent(dim, tag, parentDim, parentTag);
			std::cout << " - parent entity (" << parentDim << "," << parentTag << ")\n";
		}

		// * List all types of elements making up the mesh of the entity:
		for(auto elemType : elemTypes) {
			std::string name;
			int d, order, numv, numpv;
			std::vector<double> param;
			gmsh::model::mesh::getElementProperties(elemType, name, d, order, numv, param, numpv);
			std::cout << " - Element type: " << name << ", order " << order << "\n";
			std::cout << "   with " << numv << " nodes in param coord: (";
			for(auto p : param)
				std::cout << p << " ";
			std::cout << ")\n";
		}
	}
}

void add_post_processing_data() {
#if 0 // On nodes
	{
		const auto viewTag = gmsh::view::add("myview");
		std::vector<size_t> nodeTags;
		std::vector<double> nodeCoords;
		std::vector<double> parametricCoord; // unused
		gmsh::model::mesh::getNodes(nodeTags, nodeCoords, parametricCoord);

		for(int coord = 0; coord < 3; ++coord) {
			std::vector<std::vector<double>> data;
			// test: store x, y and z coordinate as per-node data
			for(size_t i = 0; i < nodeTags.size(); ++i) {
				data.push_back({nodeCoords[3 * i + coord]});
			}
			gmsh::view::addModelData(viewTag, coord, "myrect", "NodeData", nodeTags, data, 0, 1);
		}

		gmsh::view::write(viewTag, "myrect.pos");
	}
#else // On elements
	{
		const auto viewTag = gmsh::view::add("myview");
		std::vector<size_t> elemTags;
		std::vector<size_t> elemNodeTags;
		gmsh::model::mesh::getElementsByType(2, elemTags, elemNodeTags);
		std::vector<std::vector<double>> data;
		// set element index as data
		for(size_t i = 0; i < elemTags.size(); ++i) {
			data.push_back({static_cast<double>(i)});
		}
		gmsh::view::addModelData(viewTag, 0, "myrect", "ElementData", elemTags, data, 0, 1);

		gmsh::view::write(viewTag, "myrect.pos");
	}
#endif
}

// TODO: This should also return information about the edges in between
std::unordered_map<size_t, std::unordered_set<size_t>> compute_connectivity() {
	// Adapted for 2D from https://gitlab.onelab.info/gmsh/gmsh/blob/gmsh_4_13_1/examples/api/neighbors.py

	const auto triangle = gmsh::model::mesh::getElementType("Triangle", 1);
	// fmt::print("triangle has type: {}\n", triangle);
	std::vector<size_t> triangleTags;     // triangle ids (n)
	std::vector<size_t> triangleNodeTags; // node (point) ids of the triangles (3*n)
	gmsh::model::mesh::getElementsByType(triangle, triangleTags, triangleNodeTags);

	// fmt::print("triangles: {}\n", fmt::join(triangleTags, ", "));
	// fmt::print("triangle nodes: {}\n", fmt::join(triangleNodeTags, ", "));

	// Get edges of the triangles
	// TODO: This is just the same as the triangle nodes, split into individual pairs
	// => gmsh also offers the option of creating unique line objects for each edge
	// (https://gitlab.onelab.info/gmsh/gmsh/blob/gmsh_4_13_1/tutorials/c++/x7.cpp),
	// which then have a tag => do we want that?
	std::vector<size_t> edgeTags;
	gmsh::model::mesh::getElementEdgeNodes(triangle, edgeTags);
	// fmt::print("edges: {}\n", fmt::join(edgeTags, ", "));

	std::vector<edge> edges;
	// TODO: No need for a vector (at most 2 neighbors)
	std::unordered_map<edge, std::vector<size_t>> edgeToTriangles;
	for(size_t i = 0; i < edgeTags.size(); i += 2) {
		const edge e(edgeTags[i], edgeTags[i + 1]);
		edges.push_back(e);
		// const auto tri = triangleTags[i / 2];
		const auto tri = triangleTags.at(i / (2 * 3));
		edgeToTriangles[e].push_back(tri);
	}

	// Print edges and their triangles
	// for(const auto& [e, tris] : edgeToTriangles) {
	// 	fmt::print("Edge ({}, {}) has triangles: {}\n", e.from(), e.to(), fmt::join(tris, ", "));
	// }

	// TODO: Using a set is overkill, since we have at most 3 neighbors
	std::unordered_map<size_t, std::unordered_set<size_t>> triangleToTriangles;
	for(size_t i = 0; i < edges.size(); ++i) {
		const auto& e = edges[i];
		const auto t = triangleTags[i / 3];
		for(const auto& tri : edgeToTriangles[e]) {
			if(tri != t) { triangleToTriangles[t].insert(tri); }
		}
	}

	// Print connectivity:
	// for(const auto& [t, neighbors] : triangleToTriangles) {
	// 	fmt::print("Triangle {} has neighbors: {}\n", t, fmt::join(neighbors, ", "));
	// }

	return triangleToTriangles;
}

int main() {
	gmsh::initialize();

	// gmsh::model::add("myrect");
	// gmsh::model::occ::addRectangle(0, 0, 0, 1, 1, 1);

	// load model from file
	// const auto model_file = "./thingymajig.msh";
	// const auto model_file = "./Stanford_Bunny_blender_remesh_low_poly.stl";
	// const auto model_file = "./Stanford_Bunny_blender_remesh_med_poly.stl";
	const auto model_file = "./Stanford_Bunny_blender_remesh_hi_poly.stl";
	gmsh::open(model_file);
	const bool already_meshed = std::string(model_file).ends_with(".msh");
	gmsh::model::occ::synchronize();

	if(!already_meshed) {
		// Set mesh size - this affects how many elements are generated
		gmsh::option::setNumber("Mesh.MeshSizeFactor", 0.5);
		// gmsh::option::setNumber("Mesh.MeshSizeFactor", 3);
		gmsh::model::mesh::generate(2);

		// Partition mesh: https://gitlab.onelab.info/gmsh/gmsh/blob/gmsh_4_13_1/tutorials/c++/t21.cpp
		gmsh::option::setNumber("Mesh.PartitionCreateGhostCells", 1);
		gmsh::model::mesh::partition(4);
		// gmsh::model::mesh::partition(2);

		gmsh::write(std::string(model_file).replace(std::string(model_file).find(".stl"), 4, ".msh"));
	}

	// add_post_processing_data();
	// print_entities();

	// => As I understood it so far, in Peter approach:
	// - "Dynamic data" (e.g. temperature) is stored separately from inner/outer cells, in a single array
	// - Inner and outer cells are stored separately, and each contain a reference to their dynamic index,
	//   as well as a list of neighboring cells, also in terms of their dynamic index
	// - Outer cells additionally store a list of ghost cells from which they read, as well as a list of ghost cells
	//   where they copy their values to

	// TODO: This struct could contain anything - user defined
	struct dynamic_cell_data {
		float external_flow = 0.0;
		float current_energy = 0.0;
		float total_flux = 0.0;
	};

	struct inner_cell {
		uint64_t dynamic_id;

		// Dynamic ids of connected cells within the same partition  - may include inner and outer cells
		uint64_t neighbors[3];
		uint8_t num_neighbors;

		// TODO: Stuff below is not needed on device
		int element_tag;
		uint32_t partition;
	};

	struct outer_cell {
		uint64_t dynamic_id;

		// Dynamic ids of connected cells within the same partition - may include inner and outer cells
		uint64_t neighbors[2];
		uint8_t num_neighbors;

		uint64_t read_transfers[2];
		uint8_t num_read_transfers;

		uint64_t write_transfers[2]; // TODO: There can be at most 2 other partitions that read from that cell, right?
		uint8_t num_write_transfers;

		// TODO: Stuff below is not needed on device
		int element_tag;
		uint32_t partition;
	};

	struct partition {
		std::vector<uint64_t> cells; //< includes inner and outer cells
		std::vector<uint64_t> outer_cells;
		std::vector<uint64_t> ghost_cells;                // belong to other partitions
		std::unordered_set<uint64_t> neighbor_partitions; // TODO: Use pointers instead?

		// For Celerity
		size_t outer_offset;
		size_t inner_offset;
		size_t dyn_offset;
		size_t transfer_offset;
		size_t num_transfers;
	};

	std::vector<dynamic_cell_data> dynamic_data;
	std::vector<dynamic_cell_data> transfer_data;
	std::vector<inner_cell> inner_cells;
	std::vector<outer_cell> outer_cells;
	std::vector<partition> partitions;

	// THE ALGORITHM:
	// - Compute connectivity between all elements and edges
	// - Collect element tags for each partition, as well as ghost cells
	// - For each partition, identify its outer cells (= cells that neighbor ghost cells)
	// - Identify (somehow?) neighboring partitions
	//		(Maybe through ghost cells?)
	// - For each pair of neighboring partitions, pick a source and destination
	//		- The destination intersects its ghost cells with the source's outer cells
	//		- These cells need have a copy stored stored in a special send-buffer for that partition pair and direction
	//		- The outer cells are marked as having to copy data into those cells

	fmt::print("Compute connectivity\n");
	const auto triangleConnectivity = compute_connectivity();

	fmt::print("Group into partitions\n");
	// Group cells and ghost cells into partitions
	std::vector<std::pair<int, int>> entities;
	gmsh::model::getEntities(entities);
	for(const auto& [dim, tag] : entities) {
		if(dim != 2) continue;
		std::vector<int> belongs_to_partitions;
		gmsh::model::getPartitions(dim, tag, belongs_to_partitions);
		const size_t num_partitions = gmsh::model::getNumberOfPartitions();
		if(num_partitions > 0 && belongs_to_partitions.empty()) continue;
		if(belongs_to_partitions.size() > 1) {
			// Not sure what this means
			throw std::runtime_error("Found entity belonging to more than one partition - it is possible after all?!");
		}
		if(num_partitions == 0) {
			// If we don't have partitions, create an implicit one (logic below expects it)
			belongs_to_partitions.push_back(1);
		}

		// Indexing starts at 1
		if(partitions.size() < static_cast<uint64_t>(belongs_to_partitions[0])) { partitions.resize(belongs_to_partitions[0]); }
		auto& partition = partitions[belongs_to_partitions[0] - 1];

		const auto triangle = gmsh::model::mesh::getElementType("Triangle", 1);
		std::vector<size_t> triangleTags;     // triangle ids (n)
		std::vector<size_t> triangleNodeTags; // node (point) ids of the triangles (3*n)

		// I guess the element type implies the dimension
		gmsh::model::mesh::getElementsByType(triangle, triangleTags, triangleNodeTags, tag);

		int parentDim, parentTag;
		gmsh::model::getParent(dim, tag, parentDim, parentTag);
		if(num_partitions == 0 || (parentDim != -1 && parentTag != -1)) {
			// assert(partition.cells.empty());
			// partition.cells = std::move(triangleTags);
			// Turns out that multiple entities can belong to the same partition!
			partition.cells.insert(partition.cells.end(), triangleTags.begin(), triangleTags.end());
		} else {
			// Note that ghost cells are based on nodes, not edges, so initially this contains too many cells (will be
			// pruned below)
			// assert(partition.ghost_cells.empty());
			// partition.ghost_cells = std::move(triangleTags);
			partition.ghost_cells.insert(partition.ghost_cells.end(), triangleTags.begin(), triangleTags.end());
		}
	}

	fmt::print("Have {} partitions\n", partitions.size());
	assert(gmsh::model::getNumberOfPartitions() == 0 || partitions.size() == static_cast<size_t>(gmsh::model::getNumberOfPartitions()));

	// Sanity check
	for(auto& p : partitions) {
		assert(!p.cells.empty());
		assert(gmsh::model::getNumberOfPartitions() == 0 || !p.ghost_cells.empty());
	}
	assert(std::accumulate(partitions.begin(), partitions.end(), uint64_t{0}, [](uint64_t sum, const auto& p) { return sum + p.cells.size(); })
	       == triangleConnectivity.size());

	// cell tag to partition id (zero-based index)
	// TODO: Can't this be a vector (or dense_map)? We map every cell, right?
	std::unordered_map<uint64_t, uint64_t> outerCellToPartition;

	fmt::print("Identify inner and outer cells\n");
	// Identify inner and outer cells
	for(auto& p : partitions) {
		std::sort(p.ghost_cells.begin(), p.ghost_cells.end()); // TODO: Needed for blender remesh of stanford bunny?!
		assert(std::is_sorted(p.ghost_cells.begin(), p.ghost_cells.end()));
		assert(std::is_sorted(p.outer_cells.begin(), p.outer_cells.end()));
		p.outer_offset = outer_cells.size();
		p.inner_offset = inner_cells.size();
		p.dyn_offset = dynamic_data.size();
		for(const auto cell : p.cells) {
			bool is_outer = false;
			for(auto& neighbor : triangleConnectivity.at(cell)) {
				// Is it an outer cell? (cells that share an edge with a cell from another partition)
				if(std::binary_search(p.ghost_cells.begin(), p.ghost_cells.end(), neighbor)) {
					p.outer_cells.push_back(cell);
					outerCellToPartition[cell] = &p - partitions.data();
					fmt::print("Partition {} has outer cell {}\n", &p - partitions.data(), cell);
					is_outer = true;
					// Don't allocate dynamic data yet, because we want all outer cells to be contiguous
					break;
				}
			}
			if(!is_outer) {
				inner_cells.push_back({});
				inner_cells.back().dynamic_id = dynamic_data.size();
				dynamic_data.push_back({});
				inner_cells.back().element_tag = cell;
				inner_cells.back().partition = &p - partitions.data(); // TODO: Do we even need this?
			}
		}

		// Allocate dynamic data for outer cells/
		for(const auto cell : p.outer_cells) {
			outer_cells.push_back({});
			outer_cells.back().dynamic_id = dynamic_data.size();
			dynamic_data.push_back({});
			outer_cells.back().element_tag = cell;
			outer_cells.back().partition = &p - partitions.data(); // TODO: Do we even need this?
		}

		// Now prune all ghost cells that do not neighbor an outer cell in this partition
		// This is required because gmsh computes ghost cells based on nodes, not edges
		auto it = std::remove_if(p.ghost_cells.begin(), p.ghost_cells.end(), [&](const auto& cell) {
			for(auto& neighbor : triangleConnectivity.at(cell)) {
				if(std::binary_search(p.outer_cells.begin(), p.outer_cells.end(), neighbor)) { return false; }
			}
			// fmt::print("Pruning ghost cell {} from partition id {}\n", cell, &p - partitions.data());
			return true;
		});
		fmt::print("Pruning {}/{} ghost cells from partition id {}\n", std::distance(it, p.ghost_cells.end()), p.ghost_cells.size(), &p - partitions.data());
		p.ghost_cells.erase(it, p.ghost_cells.end());
	}

	fmt::print("Find neighboring partitions\n");
	// Find neighboring partitions
	for(size_t i = 0; i < partitions.size(); ++i) {
		auto& p = partitions[i];
		for(auto& cell : p.outer_cells) {
			for(auto& neighbor : triangleConnectivity.at(cell)) {
				const auto it = outerCellToPartition.find(neighbor);
				if(it != outerCellToPartition.end() && it->second != i) { p.neighbor_partitions.insert(it->second); }
			}
		}
		fmt::print("Partition id {} has neighbor ids: {}\n", i, fmt::join(p.neighbor_partitions, ", "));
	}

	// FIXME: STUPID
	const auto get_outer_cell_by_tag = [&](int tag) -> std::optional<outer_cell*> {
		const auto it = std::find_if(outer_cells.begin(), outer_cells.end(), [&](const auto& c) { return c.element_tag == tag; });
		if(it == outer_cells.end()) { return std::nullopt; }
		return &*it;
	};

	// FIXME: STUPID (only used for printing / sanity checks below though)
	const auto get_inner_cell_by_tag = [&](int tag) -> std::optional<inner_cell*> {
		const auto it = std::find_if(inner_cells.begin(), inner_cells.end(), [&](const auto& c) { return c.element_tag == tag; });
		if(it == inner_cells.end()) { return std::nullopt; }
		return &*it;
	};

	fmt::print("Compute transfers\n");
	// For each neighboring partition, intersect the neighbor's ghost cells with outer cells to find required transfers
	for(size_t i = 0; i < partitions.size(); ++i) {
		auto& p = partitions[i];
		p.transfer_offset = transfer_data.size();
		for(auto& neighbor_id : p.neighbor_partitions) {
			auto& neighbor = partitions[neighbor_id];
			for(auto& cell : p.outer_cells) {
				for(auto& neighbor_ghost_cell : neighbor.ghost_cells) {
					if(cell == neighbor_ghost_cell) {
						fmt::print("Partition id {} has to copy cell {} for partition id {}\n", i, neighbor_ghost_cell, neighbor_id);

						// FIXME: STUPID
						auto& outer_cell = *get_outer_cell_by_tag(cell).value();
						transfer_data.push_back({});
						const auto transfer_id = transfer_data.size() - 1;
						assert(outer_cell.num_write_transfers < 2);
						outer_cell.write_transfers[outer_cell.num_write_transfers++] = transfer_id;
						p.num_transfers++; // NOCOMMIT TODO: We cannot just infer this from number of outer cells, right?

						// Find all of the neighbors cells that are connected to this ghost cell
						for(auto& connected_cell : triangleConnectivity.at(neighbor_ghost_cell)) {
							if(std::binary_search(neighbor.outer_cells.begin(), neighbor.outer_cells.end(), connected_cell)) {
								auto& neighbor_outer_cell = *get_outer_cell_by_tag(connected_cell).value();
								assert(neighbor_outer_cell.num_read_transfers < 2);
								neighbor_outer_cell.read_transfers[neighbor_outer_cell.num_read_transfers++] = transfer_id;
								fmt::print("\tCell {} in partition id {} reads from copy of cel {} in partition id {}\n", connected_cell, neighbor_id,
								    neighbor_ghost_cell, i);
							}
						}
					}
				}
			}
		}
	}

	fmt::print("Build outer connectivity\n");
	// Build outer connectivity
	// TODO: Can we combine this with another step?
	for(auto& cell : outer_cells) {
		const auto neighbors = triangleConnectivity.at(cell.element_tag);
		assert(neighbors.size() <= 3);
		for(auto& neighbor : neighbors) {
			if(const auto inner_it =
			        std::find_if(inner_cells.begin(), inner_cells.end(), [&](const auto& c) { return static_cast<uint64_t>(c.element_tag) == neighbor; });
			    inner_it != inner_cells.end() && inner_it->partition == cell.partition) {
				assert(cell.num_neighbors < 2);
				cell.neighbors[cell.num_neighbors++] = inner_it->dynamic_id;
			} else if(const auto outer_it =
			              std::find_if(outer_cells.begin(), outer_cells.end(), [&](const auto& c) { return static_cast<uint64_t>(c.element_tag) == neighbor; });
			          outer_it != outer_cells.end() && outer_it->partition == cell.partition) {
				assert(cell.num_neighbors < 2);
				cell.neighbors[cell.num_neighbors++] = outer_it->dynamic_id;
			} else {
				// This is fine, it just means that the neighbor is in another partition
			}
		}
	}

	fmt::print("Build inner connectivity\n");
	// Build inner connectivity
	// FIXME: STUPID - Need to get rid of conversion between tags and indices
	for(auto& cell : inner_cells) {
		const auto neighbors = triangleConnectivity.at(cell.element_tag);
		assert(neighbors.size() <= 3);
		for(auto& neighbor : neighbors) {
			if(const auto inner_it =
			        std::find_if(inner_cells.begin(), inner_cells.end(), [&](const auto& c) { return static_cast<uint64_t>(c.element_tag) == neighbor; });
			    inner_it != inner_cells.end()) {
				assert(cell.num_neighbors < 3);
				assert(cell.partition == inner_it->partition);
				cell.neighbors[cell.num_neighbors++] = inner_it->dynamic_id;
			} else if(const auto outer_it =
			              std::find_if(outer_cells.begin(), outer_cells.end(), [&](const auto& c) { return static_cast<uint64_t>(c.element_tag) == neighbor; });
			          outer_it != outer_cells.end()) {
				assert(cell.num_neighbors < 3);
				assert(cell.partition == outer_it->partition);
				cell.neighbors[cell.num_neighbors++] = outer_it->dynamic_id;
			} else {
				throw std::runtime_error("Could not find inner neighbor cell");
			}
		}
	}

	// Print summary of each partition, which inner and outer cells they contain, and how they are connected
	for(size_t i = 0; i < partitions.size(); ++i) {
		const auto& p = partitions[i];
		fmt::print("Partition id {} has {} inner cells and {} outer cells\n", i, p.cells.size(), p.outer_cells.size());
		for(auto tag : p.cells) {
			if(const auto cell = get_inner_cell_by_tag(tag); cell.has_value()) {
				// fmt::print("\tInner cell {}: Connected to {}\n", tag, fmt::join(std::span(&(*cell)->neighbors[0], (*cell)->num_neighbors), ", "));
			} else if(const auto cell = get_outer_cell_by_tag(tag); cell.has_value()) {
				//
			} else {
				throw std::runtime_error("Could not find cell");
			}
		}
		for(auto tag : p.outer_cells) {
			const auto cell = get_outer_cell_by_tag(tag).value();
			// fmt::print("\tOuter cell {}: Connected to {}, read transfers {}, write transfers {}\n", tag,
			//     fmt::join(std::span(&cell->neighbors[0], cell->num_neighbors), ", "),
			//     fmt::join(std::span(&cell->read_transfers[0], cell->num_read_transfers), ", "),
			//     fmt::join(std::span(&cell->write_transfers[0], cell->num_write_transfers), ", "));
		}
	}


	////// SIMULATION TIME!!!!!!
	const auto viewTag = gmsh::view::add("myview");
	std::vector<size_t> elemTags;
	std::vector<size_t> elemNodeTags;
	gmsh::model::mesh::getElementsByType(2, elemTags, elemNodeTags);

	celerity::buffer<dynamic_cell_data, 1> gpu_dynamic_data{dynamic_data.data(), dynamic_data.size()};
	celerity::buffer<dynamic_cell_data, 1> gpu_transfer_data{transfer_data.data(), transfer_data.size()};
	celerity::buffer<dynamic_cell_data, 1> gpu_dynamic_data_swap{dynamic_data.data(), dynamic_data.size()};
	celerity::buffer<dynamic_cell_data, 1> gpu_transfer_data_swap{transfer_data.data(), transfer_data.size()};
	celerity::buffer<inner_cell, 1> gpu_inner_cells{inner_cells.data(), inner_cells.size()};
	celerity::buffer<outer_cell, 1> gpu_outer_cells{outer_cells.data(), outer_cells.size()};

	celerity::debug::set_buffer_name(gpu_dynamic_data, "dynamic data A");
	celerity::debug::set_buffer_name(gpu_transfer_data, "transfer data A");
	celerity::debug::set_buffer_name(gpu_dynamic_data_swap, "dynamic data B");
	celerity::debug::set_buffer_name(gpu_transfer_data_swap, "transfer data B");
	celerity::debug::set_buffer_name(gpu_inner_cells, "inner cells");
	celerity::debug::set_buffer_name(gpu_outer_cells, "outer cells");

	// NOCOMMIT NEXT STEPS:
	// - For each partition, compute start/end index in outer/inner/dynaic buffers
	// - Compute start/end in write transfer buffer
	// - Compute all required ranges in read transfer buffer => This is the one we'll have to pack for optimization

	celerity::custom_task_geometry outer_update_geometry;
	celerity::custom_task_geometry inner_update_geometry;

	using celerity::chunk;
	using celerity::range;
	using celerity::subrange;
	using celerity::detail::box;
	using celerity::detail::device_id;
	using celerity::detail::node_id;
	using celerity::detail::region;
	using celerity::detail::subrange_cast;

	std::vector<std::pair<chunk<3>, std::vector<subrange<3>>>> outer_update_read_outer_accesses;
	std::vector<std::pair<chunk<3>, std::vector<subrange<3>>>> outer_update_read_dyn_accesses;
	std::vector<std::pair<chunk<3>, std::vector<subrange<3>>>> outer_update_read_transfers_accesses;
	std::vector<std::pair<chunk<3>, std::vector<subrange<3>>>> outer_update_write_dyn_accesses;
	std::vector<std::pair<chunk<3>, std::vector<subrange<3>>>> outer_update_write_transfers_accesses;

	std::vector<std::pair<chunk<3>, std::vector<subrange<3>>>> inner_update_read_inner_accesses;
	std::vector<std::pair<chunk<3>, std::vector<subrange<3>>>> inner_update_read_dyn_accesses;
	std::vector<std::pair<chunk<3>, std::vector<subrange<3>>>> inner_update_write_dyn_accesses;

	// Since dynamic elements are interleaved between outer and inner cells across partitions, we need to compute
	// the "union access" for the expert ranger mappers.
	// TODO: Should we instead store outer/inner cell data in globally contiguous blocks?
	region<3> outer_update_dyn_writes_union;
	region<3> inner_update_dyn_writes_union;

	// TODO API: Need way of getting number of nodes
	for(size_t i = 0; i < partitions.size(); ++i) {
		const auto& p = partitions[i];
		const auto outer_sr = subrange_cast<3>(subrange<1>{p.outer_offset, p.outer_cells.size()});
		const size_t num_inner_cells = p.cells.size() - p.outer_cells.size();
		const auto inner_sr = subrange_cast<3>(subrange<1>{p.inner_offset, num_inner_cells});
		// NOCOMMIT: Hardcoded 4 devices
		outer_update_geometry.assigned_chunks.emplace_back(outer_sr, node_id(i / 4), device_id(i % 4));
		inner_update_geometry.assigned_chunks.emplace_back(inner_sr, node_id(i / 4), device_id(i % 4));

		CELERITY_CRITICAL("Partition {} has {} inner and {} outer cells. Dyn offset = {}", i, num_inner_cells, p.outer_cells.size(), p.dyn_offset);

		const auto outer_chunk = chunk<3>{outer_sr.offset, outer_sr.range, range_cast<3>(range<1>(outer_cells.size()))};
		outer_update_read_outer_accesses.push_back(std::pair{outer_chunk, std::vector{outer_sr}}); // Same as execution sr
		// Outer cell update also reads from inner cells
		outer_update_read_dyn_accesses.push_back(std::pair{outer_chunk, std::vector{subrange_cast<3>(subrange<1>{p.dyn_offset, p.cells.size()})}});
		// Outer cell's dynamic data is stored after inner cell's
		outer_update_write_dyn_accesses.push_back(
		    std::pair{outer_chunk, std::vector{subrange_cast<3>(subrange<1>{p.dyn_offset + num_inner_cells, p.outer_cells.size()})}});
		outer_update_dyn_writes_union = region_union(outer_update_dyn_writes_union, box<3>{outer_update_write_dyn_accesses.back().second[0]});
		region<1> read_transfers_region;
		region<1> write_transfers_region;
		// TODO: It's getting really confusing what a tag is and what an index is - use phantom types?
		// TODO API: Should this be something that the user can do as well? Specify custom strong index types?
		for(size_t oc = p.outer_offset; oc < p.outer_offset + p.outer_cells.size(); ++oc) {
			const auto& outer_cell = outer_cells[oc];
			for(size_t j = 0; j < outer_cell.num_read_transfers; ++j) {
				read_transfers_region = region_union(read_transfers_region, box<1>{outer_cell.read_transfers[j], outer_cell.read_transfers[j] + 1});
			}
			for(size_t j = 0; j < outer_cell.num_write_transfers; ++j) {
				write_transfers_region = region_union(write_transfers_region, box<1>{outer_cell.write_transfers[j], outer_cell.write_transfers[j] + 1});
			}
		}
		// TODO: Wait - is this even a problem? Don't we have at most N-1 contiguous transfer ranges to read?
		CELERITY_CRITICAL("Read transfers for partition {}: {}", i, read_transfers_region);
		CELERITY_CRITICAL("Write transfers for partition {}: {}", i, write_transfers_region);
		// TODO API: This should just accept a region
		std::vector<subrange<3>> read_transfers_subranges;
		std::vector<subrange<3>> write_transfers_subranges;
		std::transform(read_transfers_region.get_boxes().begin(), read_transfers_region.get_boxes().end(), std::back_inserter(read_transfers_subranges),
		    [](const auto& box) { return subrange_cast<3>(subrange<1>{box}); });
		std::transform(write_transfers_region.get_boxes().begin(), write_transfers_region.get_boxes().end(), std::back_inserter(write_transfers_subranges),
		    [](const auto& box) { return subrange_cast<3>(subrange<1>{box}); });
		outer_update_read_transfers_accesses.push_back(std::pair{outer_chunk, read_transfers_subranges});
		outer_update_write_transfers_accesses.push_back(std::pair{outer_chunk, write_transfers_subranges});

		const auto inner_chunk = chunk<3>{inner_sr.offset, inner_sr.range, range_cast<3>(range<1>(inner_cells.size()))};
		inner_update_read_inner_accesses.push_back(std::pair{inner_chunk, std::vector{inner_sr}}); // Same as execution sr
		inner_update_read_dyn_accesses.push_back(std::pair{inner_chunk, std::vector{subrange_cast<3>(subrange<1>{p.dyn_offset, p.cells.size()})}});
		inner_update_write_dyn_accesses.push_back(std::pair{inner_chunk, std::vector{subrange_cast<3>(subrange<1>{p.dyn_offset, num_inner_cells})}});
		inner_update_dyn_writes_union = region_union(inner_update_dyn_writes_union, box<3>{inner_update_write_dyn_accesses.back().second[0]});
	}

	celerity::expert_mapper outer_update_read_outer_mapper{subrange_cast<3>(subrange<1>{0, outer_cells.size()}), outer_update_read_outer_accesses};
	celerity::expert_mapper outer_update_read_dyn_mapper{subrange_cast<3>(subrange<1>{0, dynamic_data.size()}), outer_update_read_dyn_accesses};
	celerity::expert_mapper outer_update_read_transfers_mapper{subrange_cast<3>(subrange<1>{0, transfer_data.size()}), outer_update_read_transfers_accesses};
	celerity::expert_mapper outer_update_write_dyn_mapper{outer_update_dyn_writes_union, outer_update_write_dyn_accesses};
	celerity::expert_mapper outer_update_write_transfers_mapper{subrange_cast<3>(subrange<1>{0, transfer_data.size()}), outer_update_write_transfers_accesses};

	celerity::expert_mapper inner_update_read_inner_mapper{subrange_cast<3>(subrange<1>{0, inner_cells.size()}), inner_update_read_inner_accesses};
	celerity::expert_mapper inner_update_read_dyn_mapper{subrange_cast<3>(subrange<1>{0, dynamic_data.size()}), inner_update_read_dyn_accesses};
	celerity::expert_mapper inner_update_write_dyn_mapper{inner_update_dyn_writes_union, inner_update_write_dyn_accesses};

	celerity::queue queue;

	// Set initial value
	dynamic_data[static_cast<size_t>(dynamic_data.size() * 0.20)].external_flow = 10;
	dynamic_data[static_cast<size_t>(dynamic_data.size() * 0.40)].external_flow = 10;
	dynamic_data[static_cast<size_t>(dynamic_data.size() * 0.60)].external_flow = 10;
	dynamic_data[static_cast<size_t>(dynamic_data.size() * 0.80)].external_flow = 10;

	auto dynamic_data_swap = dynamic_data;
	auto transfer_data_swap = transfer_data;

	const float dt = 0.25;

	const size_t num_steps = 10000;
	size_t write_step = 0;
	const size_t write_every_n = 250;
	fmt::print("Start simulation, {} steps\n", num_steps);
	for(size_t i = 0; i < num_steps; ++i) {
		if(gpu_outer_cells.get_range().size() > 0) {
			queue.submit([&](celerity::handler& cgh) {
				// celerity::accessor read_outer{gpu_outer_cells, cgh, celerity::access::all{}, celerity::read_only};
				// celerity::accessor read_dyn{gpu_dynamic_data, cgh, celerity::access::all{}, celerity::read_only};
				// celerity::accessor read_transfers{gpu_transfer_data, cgh, celerity::access::all{}, celerity::read_only};
				// celerity::accessor write_dyn{gpu_dynamic_data_swap, cgh, celerity::access::all{}, celerity::write_only, celerity::no_init};
				// celerity::accessor write_transfers{gpu_transfer_data_swap, cgh, celerity::access::all{}, celerity::write_only, celerity::no_init};
				celerity::accessor read_outer{gpu_outer_cells, cgh, outer_update_read_outer_mapper, celerity::read_only};
				celerity::accessor read_dyn{gpu_dynamic_data, cgh, outer_update_read_dyn_mapper, celerity::read_only};
				celerity::accessor read_transfers{gpu_transfer_data, cgh, outer_update_read_transfers_mapper, celerity::read_only};
				celerity::accessor write_dyn{gpu_dynamic_data_swap, cgh, outer_update_write_dyn_mapper, celerity::write_only, celerity::no_init};
				celerity::accessor write_transfers{gpu_transfer_data_swap, cgh, outer_update_write_transfers_mapper, celerity::write_only, celerity::no_init};

				celerity::debug::set_task_name(cgh, "outer update");
				// cgh.parallel_for(gpu_outer_cells.get_range(), [=](celerity::id<1> itm) {
				cgh.parallel_for(outer_update_geometry, [=](celerity::id<1> itm) {
					const auto& cell = read_outer[itm];
					const auto& dyn_data = read_dyn[cell.dynamic_id];

					float total_flux = dyn_data.external_flow;
					for(size_t j = 0; j < cell.num_neighbors; ++j) {
						const auto& neighbor = read_dyn[cell.neighbors[j]];
						total_flux += (neighbor.current_energy - dyn_data.current_energy) * dt; // TODO: Transfer coefficient etc
					}
					for(size_t j = 0; j < cell.num_read_transfers; ++j) {
						const auto& transfer = read_transfers[cell.read_transfers[j]];
						total_flux += (transfer.current_energy - dyn_data.current_energy) * dt; // TODO: Transfer coefficient etc
					}

					auto& dyn_write = write_dyn[cell.dynamic_id];
					dyn_write.current_energy = dyn_data.current_energy + total_flux;
					dyn_write.total_flux = dyn_data.total_flux + std::abs(total_flux);

					// Write transfers
					for(size_t j = 0; j < cell.num_write_transfers; ++j) {
						write_transfers[cell.write_transfers[j]].current_energy = dyn_write.current_energy;
						write_transfers[cell.write_transfers[j]].total_flux = dyn_write.total_flux;
					}
				});
			});
		}

		queue.submit([&](celerity::handler& cgh) {
			// celerity::accessor read_inner{gpu_inner_cells, cgh, celerity::access::all{}, celerity::read_only};
			// celerity::accessor read_dyn{gpu_dynamic_data, cgh, celerity::access::all{}, celerity::read_only};
			// celerity::accessor write_dyn{gpu_dynamic_data_swap, cgh, celerity::access::all{}, celerity::write_only, celerity::no_init};
			celerity::accessor read_inner{gpu_inner_cells, cgh, inner_update_read_inner_mapper, celerity::read_only};
			celerity::accessor read_dyn{gpu_dynamic_data, cgh, inner_update_read_dyn_mapper, celerity::read_only};
			celerity::accessor write_dyn{gpu_dynamic_data_swap, cgh, inner_update_write_dyn_mapper, celerity::write_only, celerity::no_init};

			celerity::debug::set_task_name(cgh, "inner update");
			cgh.parallel_for(inner_update_geometry, [=](celerity::id<1> itm) {
				const auto& cell = read_inner[itm];
				const auto& dyn_data = read_dyn[cell.dynamic_id];

				float total_flux = dyn_data.external_flow;
				for(size_t j = 0; j < cell.num_neighbors; ++j) {
					const auto& neighbor = read_dyn[cell.neighbors[j]];
					total_flux += (neighbor.current_energy - dyn_data.current_energy) * dt; // TODO: Transfer coefficient, etc...
				}

				auto& dyn_write = write_dyn[cell.dynamic_id];
				dyn_write.current_energy = dyn_data.current_energy + total_flux;
				dyn_write.total_flux = dyn_data.total_flux + std::abs(total_flux);
			});
		});

		std::swap(gpu_dynamic_data, gpu_dynamic_data_swap);
		std::swap(gpu_transfer_data, gpu_transfer_data_swap);

		if(i % write_every_n == 0) {
			queue.submit([&](celerity::handler& cgh) {
				// TODO: Read this or _swap?
				celerity::accessor read_dyn{gpu_dynamic_data, cgh, celerity::access::all{}, celerity::read_only_host_task};
				cgh.host_task(celerity::once, [=, &write_step]() {
					fmt::print("Step {}/{}\n", i, num_steps);

					// Write dynamic data
					std::vector<std::vector<double>> data;
					for(size_t i = 0; i < elemTags.size(); ++i) {
						if(const auto cell = get_inner_cell_by_tag(elemTags[i]); cell.has_value()) {
							data.push_back({read_dyn[(*cell)->dynamic_id].current_energy});
						} else if(const auto cell = get_outer_cell_by_tag(elemTags[i]); cell.has_value()) {
							data.push_back({read_dyn[(*cell)->dynamic_id].current_energy});
						} else {
							throw std::runtime_error("Could not find cell");
						}
					}
					std::string name;
					gmsh::model::getCurrent(name);
					// TODO: What is step and what is time?
					gmsh::view::addModelData(viewTag, write_step++, name, "ElementData", elemTags, data, 0, 1);
				});
			});
		}

#if 0
		// Update outer cells
		for(auto& cell : outer_cells) {
			const auto& dyn_data = dynamic_data[cell.dynamic_id];

			double total_flux = dyn_data.external_flow;
			for(size_t j = 0; j < cell.num_neighbors; ++j) {
				const auto& neighbor = dynamic_data[cell.neighbors[j]];
				total_flux += (neighbor.current_energy - dyn_data.current_energy) * dt; // TODO: Transfer coefficient etc

				if(std::isnan(total_flux)) {
					fmt::print("NAN at cell {}. current energy: {}, neighbor: {}. external flow: {}\n", cell.element_tag, dyn_data.current_energy,
					    neighbor.current_energy, dyn_data.external_flow);
					abort();
				}
			}
			for(size_t j = 0; j < cell.num_read_transfers; ++j) {
				const auto& transfer = transfer_data[cell.read_transfers[j]];
				total_flux += (transfer.current_energy - dyn_data.current_energy) * dt; // TODO: Transfer coefficient etc
			}
			// if(total_flux > 0) {
			// 	fmt::print("i={}: Positive flux at outer cell {}. current energy: {:.1f}, total flux: {:.1f}\n", i,
			// 	    cell.element_tag, dyn_data.current_energy, total_flux);
			// }

			// if(std::isinf(total_flux)) {
			// 	fmt::print("INF at cell {}. current energy: {}, total flux: {}\n", cell.element_tag,
			// 	    dyn_data.current_energy, total_flux);
			// 	abort();
			// }

			auto& dyn_write = dynamic_data_swap[cell.dynamic_id];
			dyn_write.current_energy = dyn_data.current_energy + total_flux;
			dyn_write.total_flux = dyn_data.total_flux + std::abs(total_flux);

			// Write transfers
			for(size_t j = 0; j < cell.num_write_transfers; ++j) {
				// TODO: Peter sets this to dyn_data, not dyn_write - ???
				transfer_data_swap[cell.write_transfers[j]].current_energy = dyn_write.current_energy;
				transfer_data_swap[cell.write_transfers[j]].total_flux = dyn_write.total_flux;
			}
		}

		// Update inner cells
		for(auto& cell : inner_cells) {
			const auto& dyn_data = dynamic_data[cell.dynamic_id];

			double total_flux = dyn_data.external_flow;
			for(size_t j = 0; j < cell.num_neighbors; ++j) {
				const auto& neighbor = dynamic_data[cell.neighbors[j]];
				total_flux += (neighbor.current_energy - dyn_data.current_energy) * dt; // TODO: Transfer coefficient, etc...
			}

			// if(total_flux > 0) {
			// 	fmt::print("i={}: Positive flux at cell {}. current energy: {}, total flux: {}\n", i, cell.element_tag,
			// 	    dyn_data.current_energy, total_flux);
			// }

			auto& dyn_write = dynamic_data_swap[cell.dynamic_id];
			dyn_write.current_energy = dyn_data.current_energy + total_flux;
			dyn_write.total_flux = dyn_data.total_flux + std::abs(total_flux);
		}

		// Swap data
		std::swap(dynamic_data, dynamic_data_swap);
		std::swap(transfer_data, transfer_data_swap);

		if(i % write_every_n == 0) {
			// Write dynamic data
			std::vector<std::vector<double>> data;
			for(size_t i = 0; i < elemTags.size(); ++i) {
				if(const auto cell = get_inner_cell_by_tag(elemTags[i]); cell.has_value()) {
					data.push_back({dynamic_data[(*cell)->dynamic_id].current_energy});
				} else if(const auto cell = get_outer_cell_by_tag(elemTags[i]); cell.has_value()) {
					data.push_back({dynamic_data[(*cell)->dynamic_id].current_energy});
				} else {
					throw std::runtime_error("Could not find cell");
				}
			}
			std::string name;
			gmsh::model::getCurrent(name);
			// TODO: What is step and what is time?
			gmsh::view::addModelData(viewTag, i, name, "ElementData", elemTags, data, 0, 1);
		}
#endif
	}

	queue.submit([&](celerity::handler& cgh) {
		// TODO: Read this or _swap?
		celerity::accessor read_dyn{gpu_dynamic_data, cgh, celerity::access::all{}, celerity::read_only_host_task};
		cgh.host_task(celerity::once, [=]() {
			hash hsh;
			for(size_t i = 0; i < dynamic_data.size(); ++i) {
				hsh.add(read_dyn[i].current_energy);
			}
			fmt::print("Hash: {:x}\n", hsh.get());
		});
	});

	queue.wait(celerity::experimental::barrier);

	gmsh::option::setNumber("PostProcessing.Binary", 1); // TODO: Doesn't do anything..?
	gmsh::view::write(viewTag, "heat_transfer.pos");     // NOCOMMIT Only on master

	gmsh::finalize();

	return 0;
}
